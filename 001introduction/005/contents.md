# 1. 学習対象のモデルを定義する (2)

Chainerでは学習可能なモデルをLinkとよびます。

ディープラーニングで利用される代表的なLinkは `chainer.links` でサポートされています。
また，自分で新しいLinkを作ることもできます。

以降では，この `chainer.links` を `L` として使えるようにします。


```
from chainer import links as L
```

もっと基本的なLinkはLinearとよばれるLinkです。
Linearは全ての入力と出力がつながっているようなニューラルネットワークを表します。
Linearはニューラルネットワークの文脈では総結合層，数学の用語では線形変換，アフィン変換とよびます。
たとえば，次の例では5個のユニットから，2個のユニットへの変換を表します。

```
lin = L.Linear(5, 2)
```

この `lin` はLinkオブジェクトですが，次のように関数呼び出しをすることができます。
（この関数呼び出しは `__call__` で定義されており，演算子オーバーロードで実現されています。）

```
import numpy as np
from chainer import Variable

lin = L.Linear(5, 2)
x = Variable(np.ones((3, 5), dtype=np.float32))
y1 = lin(x)
```

この `numpy` ， `Variable` については後で詳しく説明します。
この例である`np.ones((3, 5), dtype=np.float32)` は3行5列で全ての値が1であるような行列を作ります。
`Variable` はその値に加えて学習に必要な情報が埋め込まれているオブジェクトとだけ覚えてください。
つまりここでは3個の5次元のベクトルを用意し，それをVariableというオブジェクトにセットし，
それを `lin` の引数として与えて，出力を `y` として計算しています。
`lin`は5次元の入力を2次元の出力へ変換する関数なので，`y`は3個の2次元のベクトルになります。


## 線形変換，アフィン変換 (*)

線形変換（アフィン変換）は次のように表される変換です。

```math
\begin{align}
f(x; θ) &= Wx + b \\
θ &= (W, b)
\end{align}
```

例えば上記例のLinearは，5次元のベクトルから2次元のベクトルへの線形変換を表します。

# 課題

上記の例で，出力を4次元にし，それを出力してください。


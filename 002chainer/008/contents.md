# Chainerの基本：Optimization

次に学習のエンジンである最適化を紹介します。

最適化は，与えられた目的関数$F(x)$の最小値または極小値およびそれを達成する変数xを探す問題です。

機械学習は最適化を使ってパラメータを推定，つまり学習を実現します。
この実現のために，作ったモデルの推定結果$y'=F(x; \theta)$と望ましい結果$y'$の差を測る損失関数$l(y', y)$を用意します。
損失関数は推定した結果が望ましい結果であれば0，そうでなければ大きな正の値をとるような関数です。
例えば回帰問題などでは二乗誤差$l(y', y) = (y' - y)^2$を使い，分類問題ではクロスエントロピー誤差 $-p(y) \log{p(y')}$を使います。

学習データセット${(x_i, y_i)}$が与えられた時，この学習データセットに対して損失関数の和が最小になるようなパラメータを探せば，それは多くの学習データを望ましい結果で推定していることになります。

```math
L(\theta) = \sum_i l(F(x_i; \theta), y_i)
```

また，学習データに依存しないような事前知識を正則化項$R(\theta)$として入れることもできます。

```math
L(\theta) = R(\theta) + \sum_i l(F(x_i; \theta), y_i)
```


これらの目的関数を最小化すれば，多くの学習データをうまく推定でき，事前知識の制約も満たすようなパラメータを求めることができます。

## Memo

最小値，極小値

全ての $x$ について $F(x) >= F(x^\*)$ を満たすような $F(x^\*)$ を最小値とよび，それを達成する $x^\*$ を最小解とよびます。
一方 $x$ の近傍を $R(x)$ とした時，$x \in R(x^\*) $ について $F(x)>=F(x^\*a)$ を満たすような $F(x^\*)$ を極小値とよび，それを達成する $x^\*$ を極小解とよびます。
目的関数が凸関数のような性質をもっていない場合，最小解を見つけることは一般に難しく極小解を見つけることになります。
一方でニューラルネットワークの学習における最適化の場合，殆どの極小解は最小解と殆ど変わらないほど性能が良いことが予想されています[link](https://arxiv.org/abs/1412.0233)。


Chainerでは様々な最適化Optimizerがchainer.optimizersで実装されています。
Optimizerを使うにはoptimizerを初期化し，次にoptimizerの最適化対象となるlinkをsetup()で設定します。

```
from chainer import optimizers

model = F.Classifier(MyLink())
optimizer = optimizers.Adam()
optimizer.use_cleargrads()
optimizer.setup(model)
```

この場合，modelというlinkが最適化対象になります。


初期化の際，いくつかパラメータを選べます。
これらのパラメータはハイパーパラメータとよばれ，上記の最適化に使うものですから，自動決定できないパラメータです。
そのためハイパーパラメーターはユーザーが指定するか，決められた候補の中を全部試すか，別の推定手法を使う必要があります。

Chainerが用意しているoptimizerの中で代表的なものは次の三つです。

* SGD
* Adam
* RMSProp

どれを使えばよいかはそれぞれ異なる最適化手法に基づいているので一概にいえませんが，安定して最適化できるのでAdam，ハイパーパラメータを選ぶが安定して精度が出やすいのはRMSPropという特徴があります。SGDは最も単純な更新則にもとづいており上記の二つの手法に比べると性能は悪くデバッグ目的以外では使う必要はありません。

optimizerの使い方は三つあります。後の方がより使いやすくカスタマイズしにくい方法になります。

* ユーザーがbackward()などで勾配を求めて，引数なしのupdate()を呼び出します。この場合，cleargrads()を最初に呼ぶ必要があります。

```
model.cleargrads()
loss.backward()
optimizer.update()
```

* 損失関数をupdate()に渡す。この場合，cleargrads()はupdate内で自動的によばれます。そのためcleargradsのよび忘れがなく簡潔に書けます。

```
def lossfun(args...):
    ...
    return loss
optimizer.update(lossfun, args...)
```

* Trainerを利用する

これについては後の章で紹介します。

後の方法になるほど，より簡潔に書くことができます。
一方で細かく最適化を制御したい（例えば，直接gradを操作したい）場合は最初の方法を使うことができます。

## 課題

SGD最適化は関数$F(x; s)$のパラメータsについての勾配が$v$の時

```math
s := s - a v
```

とすることで最適化を行います，但しa>0は学習律とよばれるハイパーパラメータです。

```
def f(x):
    return 5.*x + 10

x = np.linspace(-10, 10, num=1001)
y = f(x) + 5.*np.random.randn()
```

で与えられるデータセット$(x, y)$について最小二乗誤差（F.mean_squared_error）を損失関数として使ってSGDで

```math
y = ax + b
```

の$a, b$（この場合$a=5.0, b=10$に近い値，但し乱数による誤差で必ずしも5.0, 10.0とはならない)を推定するプログラムを書け。
